{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3709310e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "\n",
    "# Function to count total assistant messages and \"i don't know\" responses\n",
    "def count_idontknow_responses(jsonl_files):\n",
    "    total_assistant_lines = 0\n",
    "    idontknow_count = 0\n",
    "    \n",
    "    for file in jsonl_files:\n",
    "        with open(file, 'r') as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    data = json.loads(line)\n",
    "                    messages = data.get(\"messages\", [])\n",
    "                    for msg in messages:\n",
    "                        if msg.get(\"role\") == \"assistant\":\n",
    "                            total_assistant_lines += 1\n",
    "                            content = msg.get(\"content\", \"\").strip().lower()\n",
    "                            if \"i don't know\" in content or \"i dont know\" in content:\n",
    "                                idontknow_count += 1\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Skipping invalid JSON line in {file}\")\n",
    "\n",
    "    return total_assistant_lines, idontknow_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "162c8cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count \"I don't know\" in ground truth answers\n",
    "def count_ground_truth_idontknow(dataset):\n",
    "    total_gt_answers = 0\n",
    "    idontknow_gt_count = 0\n",
    "\n",
    "    for sample in dataset:\n",
    "        answers = sample.get(\"answers\", {}).get(\"ans_full\", [])\n",
    "        if isinstance(answers, list):\n",
    "            for ans in answers:\n",
    "                if isinstance(ans, str):\n",
    "                    total_gt_answers += 1\n",
    "                    if \"i don't know\" in ans.lower() or \"i dont know\" in ans.lower():\n",
    "                        idontknow_gt_count += 1\n",
    "\n",
    "    return total_gt_answers, idontknow_gt_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bca95e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['sft_caption_data_case_0_zero_shot_30tokens.jsonl']\n",
      "total: 1326\n",
      "'I don't know' in responses: 965\n",
      "ratio: 0.73\n",
      "\n",
      "['sft_caption_data_case_0_zero_shot_65tokens.jsonl']\n",
      "total: 1326\n",
      "'I don't know' in responses: 965\n",
      "ratio: 0.73\n",
      "\n",
      "['sft_response_data_case_1.jsonl']\n",
      "total: 1326\n",
      "'I don't know' in responses: 648\n",
      "ratio: 0.49\n",
      "\n",
      "['sft_response_data_case_2_web_search_only.jsonl']\n",
      "total: 1326\n",
      "'I don't know' in responses: 433\n",
      "ratio: 0.33\n",
      "\n",
      "['sft_response_data_case_3_image_search_only.jsonl']\n",
      "total: 1326\n",
      "'I don't know' in responses: 651\n",
      "ratio: 0.49\n",
      "\n",
      "['sft_response_data_case_4_image_web.jsonl']\n",
      "total: 1326\n",
      "'I don't know' in responses: 424\n",
      "ratio: 0.32\n",
      "\n",
      "['sft_response_data_case_5_web_search_rephrase.jsonl']\n",
      "total: 1326\n",
      "'I don't know' in responses: 434\n",
      "ratio: 0.33\n",
      "\n",
      "['sft_response_data_case_5_web_search_rephrase.jsonl']\n",
      "total: 1326\n",
      "'I don't know' in responses: 434\n",
      "ratio: 0.33\n"
     ]
    }
   ],
   "source": [
    "jsonl_files = glob.glob('sft_caption_data_case_0_zero_shot_30tokens.jsonl')\n",
    "total, idk = count_idontknow_responses(jsonl_files)\n",
    "print(f\"\\n{jsonl_files}\\ntotal: {total}\")\n",
    "print(f\"'I don't know' in responses: {idk}\\nratio: {idk / total if total > 0 else 0:.2f}\")\n",
    "\n",
    "jsonl_files = glob.glob('sft_caption_data_case_0_zero_shot_65tokens.jsonl')\n",
    "total, idk = count_idontknow_responses(jsonl_files)\n",
    "print(f\"\\n{jsonl_files}\\ntotal: {total}\")\n",
    "print(f\"'I don't know' in responses: {idk}\\nratio: {idk / total if total > 0 else 0:.2f}\")\n",
    "\n",
    "jsonl_files = glob.glob('sft_response_data_case_1.jsonl')\n",
    "total, idk = count_idontknow_responses(jsonl_files)\n",
    "print(f\"\\n{jsonl_files}\\ntotal: {total}\")\n",
    "print(f\"'I don't know' in responses: {idk}\\nratio: {idk / total if total > 0 else 0:.2f}\")\n",
    "\n",
    "jsonl_files = glob.glob('sft_response_data_case_2_web_search_only.jsonl')\n",
    "total, idk = count_idontknow_responses(jsonl_files)\n",
    "print(f\"\\n{jsonl_files}\\ntotal: {total}\")\n",
    "print(f\"'I don't know' in responses: {idk}\\nratio: {idk / total if total > 0 else 0:.2f}\")\n",
    "\n",
    "jsonl_files = glob.glob('sft_response_data_case_3_image_search_only.jsonl')\n",
    "total, idk = count_idontknow_responses(jsonl_files)\n",
    "print(f\"\\n{jsonl_files}\\ntotal: {total}\")\n",
    "print(f\"'I don't know' in responses: {idk}\\nratio: {idk / total if total > 0 else 0:.2f}\")\n",
    "\n",
    "jsonl_files = glob.glob('sft_response_data_case_4_image_web.jsonl')\n",
    "total, idk = count_idontknow_responses(jsonl_files)\n",
    "print(f\"\\n{jsonl_files}\\ntotal: {total}\")\n",
    "print(f\"'I don't know' in responses: {idk}\\nratio: {idk / total if total > 0 else 0:.2f}\")\n",
    "\n",
    "jsonl_files = glob.glob('sft_response_data_case_5_web_search_rephrase.jsonl')\n",
    "total, idk = count_idontknow_responses(jsonl_files)\n",
    "print(f\"\\n{jsonl_files}\\ntotal: {total}\")\n",
    "print(f\"'I don't know' in responses: {idk}\\nratio: {idk / total if total > 0 else 0:.2f}\")\n",
    "\n",
    "jsonl_files = glob.glob('sft_response_data_case_5_web_search_rephrase.jsonl')\n",
    "total, idk = count_idontknow_responses(jsonl_files)\n",
    "print(f\"\\n{jsonl_files}\\ntotal: {total}\")\n",
    "print(f\"'I don't know' in responses: {idk}\\nratio: {idk / total if total > 0 else 0:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e63844",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/llm_agent/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading readme: 100%|██████████| 8.42k/8.42k [00:00<00:00, 10.5MB/s]\n",
      "Downloading data: 100%|██████████| 467M/467M [03:03<00:00, 2.54MB/s] \n",
      "Downloading data: 100%|██████████| 458M/458M [03:47<00:00, 2.02MB/s] \n",
      "Downloading data:  37%|███▋      | 220M/594M [01:55<02:52, 2.16MB/s] Error while downloading from https://huggingface.co/datasets/crag-mm-2025/crag-mm-single-turn-public/resolve/711dd84fa2f1611975d476261afcb07292151923/data/validation-00002-of-00005.parquet: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Downloading data: 100%|██████████| 594M/594M [05:09<00:00, 1.92MB/s]\n",
      "Downloading data:  70%|██████▉   | 231M/330M [04:00<00:43, 2.30MB/s] Error while downloading from https://huggingface.co/datasets/crag-mm-2025/crag-mm-single-turn-public/resolve/711dd84fa2f1611975d476261afcb07292151923/data/validation-00003-of-00005.parquet: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Downloading data: 100%|██████████| 330M/330M [05:24<00:00, 1.02MB/s]\n",
      "Downloading data: 100%|██████████| 80.9M/80.9M [00:48<00:00, 1.67MB/s]\n",
      "Downloading data: 100%|██████████| 475M/475M [08:03<00:00, 983kB/s]  \n",
      "Downloading data: 100%|██████████| 477M/477M [04:08<00:00, 1.92MB/s] \n",
      "Downloading data: 100%|██████████| 646M/646M [05:52<00:00, 1.83MB/s] \n",
      "Downloading data: 100%|██████████| 388M/388M [03:30<00:00, 1.84MB/s] \n",
      "Downloading data: 100%|██████████| 79.9M/79.9M [00:30<00:00, 2.65MB/s]\n",
      "Generating validation split: 100%|██████████| 1938/1938 [00:01<00:00, 1079.19 examples/s]\n",
      "Generating public_test split: 100%|██████████| 1936/1936 [00:01<00:00, 1005.55 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"crag-mm-2025/crag-mm-single-turn-public\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4327180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1938 entries to crag_gt.jsonl\n"
     ]
    }
   ],
   "source": [
    "# ONLY GROUND TRUTH ANSWERS SAVED\n",
    "# Save to a local file (one JSON object per line)\n",
    "# dataset.to_json(\"crag_gt.jsonl\", orient=\"records\", lines=True)\n",
    "\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "\n",
    "output_path = \"crag_gt.jsonl\"\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "    for session_id, answer in zip(dataset[\"session_id\"], dataset[\"answers\"]):\n",
    "        obj = {\n",
    "            \"session_id\": session_id,\n",
    "            \"ans_full\": answer.get(\"ans_full\", [])\n",
    "        }\n",
    "        f.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Saved {len(dataset)} entries to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "370d71a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground truth answers total: 1938\n",
      "'I don't know' in ground truth answers: 0\n",
      "Ratio: 0.00\n"
     ]
    }
   ],
   "source": [
    "count_ground_truth_idontknow = count_ground_truth_idontknow(dataset)\n",
    "print(f\"\\nGround truth answers total: {count_ground_truth_idontknow[0]}\")\n",
    "print(f\"'I don't know' in ground truth answers: {count_ground_truth_idontknow[1]}\")\n",
    "print(f\"Ratio: {count_ground_truth_idontknow[1] / count_ground_truth_idontknow[0] if count_ground_truth_idontknow[0] > 0 else 0:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ba1a37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ground_truth_from_session_id(session_id):\n",
    "\n",
    "    target_session_id = session_id\n",
    "    # Find the matching example\n",
    "    match = next((item for item in dataset if item[\"session_id\"] == target_session_id), None)\n",
    "\n",
    "    # Step 3: Load and display the image\n",
    "    if match:\n",
    "        image = match[\"image\"]\n",
    "        print(\"Session ID:\", match[\"session_id\"])\n",
    "        print(\"Question:\", match[\"turns\"])\n",
    "        print(\"Answer:\", match[\"answers\"][\"ans_full\"]) # HERE\n",
    "        print(\"PIL Image Object:\", image)\n",
    "        print(\"Image size:\", image.size)\n",
    "        print(\"Image mode:\", image.mode)\n",
    "        image.show() # HERE\n",
    "    else:\n",
    "        print(\"No matching session_id found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41009bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what needs to be done\n",
    "# compare ground truth vs. our responses in scenarios\n",
    "# generate a [0, 1, -1, ...]\n",
    "# 0 as \"I don't know\" in our responses, 1 as correct answer as ground truth, -1 as our response try to answer but not correct, and so on\n",
    "\n",
    "# ultimate goal is to make the model make the most use of the found search results\n",
    "# with good reasoning, knowing when to answer, when to say \"I don't know\"\n",
    "# \n",
    "\n",
    "\n",
    "# currently image search results are not in at all. To update\n",
    "# zero-shot - be a helpful assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f43a280",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'CRAGEvaluator' has no attribute 'from_jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m LINE_NUM \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# ✅ set to 0, 1, ... to evaluate one line; or None to run all\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# === Load evaluator using local GT\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m \u001b[43mCRAGEvaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_jsonl\u001b[49m(GROUND_TRUTH_FILE)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# === Evaluate predictions\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(PREDICTIONS_FILE, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'CRAGEvaluator' has no attribute 'from_jsonl'"
     ]
    }
   ],
   "source": [
    "# METHOD 2: Launch from JSONL file (ground truth and session id only in the file)\n",
    "\n",
    "import json\n",
    "from evaluation import CRAGEvaluator\n",
    "\n",
    "# === Config\n",
    "PREDICTIONS_FILE = \"sft_caption_data_case_0_zero_shot_65tokens.jsonl\"\n",
    "GROUND_TRUTH_FILE = \"crag_gt.jsonl\"  # ✅ your local GT .jsonl file\n",
    "LINE_NUM = 2  # ✅ set to 0, 1, ... to evaluate one line; or None to run all\n",
    "\n",
    "# === Load evaluator using local GT\n",
    "evaluator = CRAGEvaluator.from_jsonl(GROUND_TRUTH_FILE)\n",
    "\n",
    "# === Evaluate predictions\n",
    "with open(PREDICTIONS_FILE, 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if LINE_NUM is not None and i != LINE_NUM:\n",
    "            continue\n",
    "        sample = json.loads(line)\n",
    "        result = evaluator.evaluate_one_jsonl_line(sample)\n",
    "        print(f\"[Line {i}] →\", result)\n",
    "        if LINE_NUM is not None:\n",
    "            break\n",
    "\n",
    "# self-quick EVALUATION\n",
    "# run_eval.py\n",
    "\n",
    "\n",
    "# # METHOD 1: Launch from dataset\n",
    "# import json\n",
    "# from datasets import load_dataset\n",
    "# from evaluation import CRAGEvaluator\n",
    "\n",
    "# # === Config ===\n",
    "# JSONL_FILE = \"sft_caption_data_case_0_zero_shot_65tokens.jsonl\"\n",
    "# LINE_NUM = 1  # ✅ Set to 0-based line index, e.g. 0 or 5, or keep as None to run all\n",
    "\n",
    "# # === Load dataset ===\n",
    "# dataset = load_dataset(\"crag-mm-2025/crag-mm-single-turn-public\", split=\"validation\")\n",
    "# evaluator = CRAGEvaluator(dataset)\n",
    "\n",
    "# # === Evaluate\n",
    "# with open(JSONL_FILE, 'r') as f:\n",
    "#     if LINE_NUM is not None:\n",
    "#         for i, line in enumerate(f):\n",
    "#             if i == LINE_NUM:\n",
    "#                 sample = json.loads(line)\n",
    "#                 result = evaluator.evaluate_one_jsonl_line(sample)\n",
    "#                 print(f\"[Line {i}] →\", result)\n",
    "#                 break\n",
    "#     else:\n",
    "#         for i, line in enumerate(f):\n",
    "#             sample = json.loads(line)\n",
    "#             result = evaluator.evaluate_one_jsonl_line(sample)\n",
    "#             print(f\"[Line {i}] →\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
